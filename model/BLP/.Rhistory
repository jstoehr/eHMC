if (is.na(cond)) {
return(list(
theta = theta, v = v, l = l,
first_turn = first_turn, div = TRUE
))
} else if (!first_turn && (cond < 0)) {
l <- i
first_turn <- TRUE
}
}
if (!first_turn) {
while (!first_turn && (l < max_length)) {
l <- l + 1
prop <- single_leapfrog(prop$theta, prop$v, grad_U, eps, inv_M, data)
cond <- as.numeric((prop$theta - theta) %*% (inv_M %*% prop$v))
if (is.na(cond)) {
return(list(
theta = theta, v = v, l = l,
first_turn = first_turn, div = TRUE
))
}
first_turn <- (cond < 0)
}
}
return(list(
theta = prop$theta, v = prop$v, l = l,
first_turn = first_turn, div = FALSE
))
}
learn_emp_dist <- function(theta, n_iter, U, grad_U, eps, L0,
inv_M, chol_M, data = NULL, max_length = 2^12) {
current_U <- U(theta, data)
dim_theta <- length(theta)
theta <- matrix(theta, n_iter + 1, dim_theta, byrow = TRUE)
ans <- data.frame(
rho = rep(0, n_iter), L = rep(L0, n_iter), l = rep(L0, n_iter),
first_turn = rep(F, n_iter), div = rep(F, n_iter)
)
for (i in 1:n_iter) {
current_v <- as.numeric(chol_M %*% rnorm(dim_theta))
current_K <- current_v %*% (inv_M %*% current_v)
L <- sample(1:L0, 1)
prop <- longest_batch(
theta[i, ], current_v, grad_U, eps, L, inv_M,
data, max_length
)
new_U <- U(prop$theta, data)
new_K <- prop$v %*% (inv_M %*% prop$v)
rho <- current_U - new_U + 0.5 * (current_K - new_K)
if (is.na(rho) || rho < log(runif(1))) {
theta[i + 1, ] <- theta[i, ]
} else {
theta[i + 1, ] <- prop$theta
current_U <- new_U
}
ans[i, ] <- c(rho, L, prop$l, prop$first_turn, prop$div)
}
return(data.frame(theta = theta[-1, ], ans))
}
leapfrog <- function(theta, v, grad_U, eps, L, inv_M, data = NULL) {
new_theta <- theta
new_v <- v - 0.5 * eps * grad_U(theta, data)
for (l in 1:(L - 1)) {
new_theta <- new_theta + eps * as.numeric(inv_M %*% new_v)
new_v <- new_v - eps * grad_U(new_theta, data)
}
new_theta <- new_theta + eps * as.numeric(inv_M %*% new_v)
return(list(
theta = new_theta,
v = new_v - 0.5 * eps * grad_U(new_theta, data)
))
}
single_leapfrog <- function(theta, v, grad_U, eps, inv_M, data) {
new_v <- v - 0.5 * eps * grad_U(theta, data)
new_theta <- theta + eps * as.numeric(inv_M %*% new_v)
new_v <- new_v - 0.5 * eps * grad_U(new_theta, data)
return(list(theta = new_theta, v = new_v))
}
U <- function(theta, data, a_mu = 10, a_sigma = 5) {
y <- data$y
T0 <- data$T
data$param_names[1, ] <- theta
mu <- as.numeric(data$param_names %>% select(starts_with("mu")))
alpha <- as.numeric(data$param_names %>% select(starts_with("mu")))
gamma <- as.numeric(data$param_names %>% select(starts_with("mu")))
h_std <- as.numeric(data$param_names %>% select(starts_with("h_std")))
# --- transformed parameter
phi <- (exp(alpha) - 1) / (exp(alpha) + 1)
sigma_2 <- exp(2 * gamma)
x <- h_std * exp(gamma)
x[1] <- x[1] / sqrt(1 - phi * phi)
x <- x + mu
for (i in 2:T) {
x[i] <- x[i] + phi * (x[i - 1] - mu)
}
x_c <- x - mu
ans <- 0.5 * sum(x + y * y / exp(x))
ans <- ans + 0.5 * h_std[1] * h_std[1]
ans <- ans + 0.5 / (sigma_2) * sum((x_c[2:T0] - phi * x_c[1:(T0 - 1)])^2)
ans <- ans - 0.5 * log(1 - phi * phi) + T0 * gamma
ans <- ans + log(a_mu * a_mu + mu * mu) + log(a_sigma * a_sigma + sigma_2)
return(ans)
}
grad_U <- function(theta, data, a_mu = 10, a_sigma = 5) {
y <- data$y
T0 <- data$T
data$param_names[1, ] <- theta
mu <- as.numeric(data$param_names %>% select(starts_with("mu")))
alpha <- as.numeric(data$param_names %>% select(starts_with("mu")))
gamma <- as.numeric(data$param_names %>% select(starts_with("mu")))
h_std <- as.numeric(data$param_names %>% select(starts_with("h_std")))
# --- transformed parameter
phi <- (exp(alpha) - 1) / (exp(alpha) + 1)
sigma <-  exp(gamma)
sigma_2 <- exp(2 * gamma)
x <- h_std * exp(gamma)
x[1] <- x[1] / sqrt(1 - phi * phi)
x <- x + mu
for (i in 2:T) {
x[i] <- x[i] + phi * (x[i - 1] - mu)
}
x_c <- x - mu
temp_diff <- x_c[2:T0] - phi * x_c[1:(T0-1)]
grad_mu <- 2 * mu / (a_mu * a_mu + mu * mu)
grad_mu <- grad_mu + (phi - 1) / sigma_2 * sum(temp_diff)
grad_mu <- grad_mu + (phi * phi - 1) / sigma_2 * x_c[1]
temp <- exp(alpha) * (phi - 1) / (sigma_2 * (1 + exp(alpha)))
grad_alpha <- temp * sum(x_c[1:(T0 - 1)] * temp_diff)
grad_alpha <- grad_alpha + 0.5 * phi
grad_alpha <- grad_alpha + phi * temp * x_c[1] * x_c[1]
grad_gamma <- -sum(temp_diff) / sigma_2 + T0 - h_std[1] * h_std[1]
grad_gamma <- grad_gamma + 2 / (1 + a_sigma * a_sigma / sigma_2)
grad_h1 <- h_std[1] + sqrt(sigma_2 / (1 - phi * phi)) * (0.5 + y[1] * exp(-x[1]))
grad_ht <- 0.5 * sigma + temp_diff/sigma
col_names_mu <- colnames(data$param_names %>% select(starts_with("mu")))
col_names_alpha <- colnames(data$param_names %>% select(starts_with("alpha")))
col_names_gamma <- colnames(data$param_names %>% select(starts_with("gamma")))
col_names_h_std <- colnames(data$param_names %>% select(starts_with("h_std")))
data$param_names[1, col_names_mu] <- grad_mu
data$param_names[1, col_names_alpha] <- grad_alpha
data$param_names[1, col_names_gamma] <- grad_gamma
data$param_names[1, col_names_h_std] <- c(grad_h1, grad_ht)
return(as.numeric(data$param_names[1, ]))
}
load("/Users/jstoehr/git/eHMC/model/SVM/SVM_PODS.RData")
data <- list(T = T.0, y = y)
load("/Users/jstoehr/git/eHMC/model/SVM/adapt_info_NUTS_SVM_diag_e_60_.RData")
param_names <- data.frame(matrix(rep(NA, length(start[1, ])), 1))
colnames(param_names) <- colnames(start)
data <- list_modify(data, param_names = param_names)
data
U(star[1,], data)
U(start[1,], data)
as.numeric(data$param_names %>% select(starts_with("h_std")))
y <- data$y
T0 <- data$T
theta <- start[1,]
data$param_names[1, ] <- theta
mu <- as.numeric(data$param_names %>% select(starts_with("mu")))
alpha <- as.numeric(data$param_names %>% select(starts_with("mu")))
gamma <- as.numeric(data$param_names %>% select(starts_with("mu")))
y <- data$y
T0 <- data$T
data$param_names[1, ] <- theta
mu <- as.numeric(data$param_names %>% select(starts_with("mu")))
alpha <- as.numeric(data$param_names %>% select(starts_with("alpha")))
gamma <- as.numeric(data$param_names %>% select(starts_with("gamma")))
h_std <- as.numeric(data$param_names %>% select(starts_with("h_std")))
# --- transformed parameter
phi <- (exp(alpha) - 1) / (exp(alpha) + 1)
sigma_2 <- exp(2 * gamma)
x <- h_std * exp(gamma)
x[1] <- x[1] / sqrt(1 - phi * phi)
x <- x + mu
U <- function(theta, data, a_mu = 10, a_sigma = 5) {
y <- data$y
T0 <- data$T
data$param_names[1, ] <- theta
mu <- as.numeric(data$param_names %>% select(starts_with("mu")))
alpha <- as.numeric(data$param_names %>% select(starts_with("alpha")))
gamma <- as.numeric(data$param_names %>% select(starts_with("gamma")))
h_std <- as.numeric(data$param_names %>% select(starts_with("h_std")))
# --- transformed parameter
phi <- (exp(alpha) - 1) / (exp(alpha) + 1)
sigma_2 <- exp(2 * gamma)
x <- h_std * exp(gamma)
x[1] <- x[1] / sqrt(1 - phi * phi)
x <- x + mu
for (i in 2:T0) {
x[i] <- x[i] + phi * (x[i - 1] - mu)
}
x_c <- x - mu
ans <- 0.5 * sum(x + y * y / exp(x))
ans <- ans + 0.5 * h_std[1] * h_std[1]
ans <- ans + 0.5 / (sigma_2) * sum((x_c[2:T0] - phi * x_c[1:(T0 - 1)])^2)
ans <- ans - 0.5 * log(1 - phi * phi) + T0 * gamma
ans <- ans + log(a_mu * a_mu + mu * mu) + log(a_sigma * a_sigma + sigma_2)
return(ans)
}
U(star[1,], data)
U(start[1,], data)
warmup <- 1
burn_in <- learn_emp_dist(start[i, ], warmup,
U, grad_U,
as.numeric(eps[i]),
L0[i],
diag(inv_M[i, ]),
diag(sqrt(inv_M[i, ])),
data = data
)
i <- 1
burn_in <- learn_emp_dist(start[i, ], warmup,
U, grad_U,
as.numeric(eps[i]),
L0[i],
diag(inv_M[i, ]),
diag(sqrt(inv_M[i, ])),
data = data
)
U <- function(theta, data, a_mu = 10, a_sigma = 5) {
y <- data$y
T0 <- data$T
data$param_names[1, ] <- theta
mu <- as.numeric(data$param_names %>% select(starts_with("mu")))
alpha <- as.numeric(data$param_names %>% select(starts_with("alpha")))
gamma <- as.numeric(data$param_names %>% select(starts_with("gamma")))
h_std <- as.numeric(data$param_names %>% select(starts_with("h_std")))
# --- transformed parameter
phi <- (exp(alpha) - 1) / (exp(alpha) + 1)
sigma_2 <- exp(2 * gamma)
x <- h_std * exp(gamma)
x[1] <- x[1] / sqrt(1 - phi * phi)
x <- x + mu
for (i in 2:T0) {
x[i] <- x[i] + phi * (x[i - 1] - mu)
}
x_c <- x - mu
ans <- 0.5 * sum(x + y * y / exp(x))
ans <- ans + 0.5 * h_std[1] * h_std[1]
ans <- ans + 0.5 / (sigma_2) * sum((x_c[2:T0] - phi * x_c[1:(T0 - 1)])^2)
ans <- ans - 0.5 * log(1 - phi * phi) + T0 * gamma
ans <- ans + log(a_mu * a_mu + mu * mu) + log(a_sigma * a_sigma + sigma_2)
return(ans)
}
grad_U <- function(theta, data, a_mu = 10, a_sigma = 5) {
y <- data$y
T0 <- data$T
data$param_names[1, ] <- theta
mu <- as.numeric(data$param_names %>% select(starts_with("mu")))
alpha <- as.numeric(data$param_names %>% select(starts_with("alpha")))
gamma <- as.numeric(data$param_names %>% select(starts_with("gamma")))
h_std <- as.numeric(data$param_names %>% select(starts_with("h_std")))
# --- transformed parameter
phi <- (exp(alpha) - 1) / (exp(alpha) + 1)
sigma <-  exp(gamma)
sigma_2 <- exp(2 * gamma)
x <- h_std * exp(gamma)
x[1] <- x[1] / sqrt(1 - phi * phi)
x <- x + mu
for (i in 2:T0) {
x[i] <- x[i] + phi * (x[i - 1] - mu)
}
x_c <- x - mu
temp_diff <- x_c[2:T0] - phi * x_c[1:(T0-1)]
grad_mu <- 2 * mu / (a_mu * a_mu + mu * mu)
grad_mu <- grad_mu + (phi - 1) / sigma_2 * sum(temp_diff)
grad_mu <- grad_mu + (phi * phi - 1) / sigma_2 * x_c[1]
temp <- exp(alpha) * (phi - 1) / (sigma_2 * (1 + exp(alpha)))
grad_alpha <- temp * sum(x_c[1:(T0 - 1)] * temp_diff)
grad_alpha <- grad_alpha + 0.5 * phi
grad_alpha <- grad_alpha + phi * temp * x_c[1] * x_c[1]
grad_gamma <- -sum(temp_diff) / sigma_2 + T0 - h_std[1] * h_std[1]
grad_gamma <- grad_gamma + 2 / (1 + a_sigma * a_sigma / sigma_2)
grad_h1 <- h_std[1] + sqrt(sigma_2 / (1 - phi * phi)) * (0.5 + y[1] * exp(-x[1]))
grad_ht <- 0.5 * sigma + temp_diff/sigma
col_names_mu <- colnames(data$param_names %>% select(starts_with("mu")))
col_names_alpha <- colnames(data$param_names %>% select(starts_with("alpha")))
col_names_gamma <- colnames(data$param_names %>% select(starts_with("gamma")))
col_names_h_std <- colnames(data$param_names %>% select(starts_with("h_std")))
data$param_names[1, col_names_mu] <- grad_mu
data$param_names[1, col_names_alpha] <- grad_alpha
data$param_names[1, col_names_gamma] <- grad_gamma
data$param_names[1, col_names_h_std] <- c(grad_h1, grad_ht)
return(as.numeric(data$param_names[1, ]))
}
burn_in <- learn_emp_dist(start[i, ], warmup,
U, grad_U,
as.numeric(eps[i]),
L0[i],
diag(inv_M[i, ]),
diag(sqrt(inv_M[i, ])),
data = data
)
emp_L <- burn_in[, "l"]
emp_L <- emp_L[which(!burn_in[, "div"])]
ehmc_sample <- eHMC(start[i, ], iter - warmup,
U, grad_U,
as.numeric(eps[i]),
emp_L,
diag(inv_M[i, ]),
diag(sqrt(inv_M[i, ])),
data = data
)
iter <- 2
ehmc_sample <- eHMC(start[i, ], iter - warmup,
U, grad_U,
as.numeric(eps[i]),
emp_L,
diag(inv_M[i, ]),
diag(sqrt(inv_M[i, ])),
data = data
)
emp_L
emp_L <- burn_in[, "l"]
emp_L
ehmc_sample <- eHMC(start[i, ], iter - warmup,
U, grad_U,
as.numeric(eps[i]),
emp_L,
diag(inv_M[i, ]),
diag(sqrt(inv_M[i, ])),
data = data
)
load("/Users/jstoehr/git/eHMC/model/BLP/NUTS_BLP_diag_e_80_.RData")
U <- function(theta, data, sd = 10) {
temp <- data$x %*% theta
return(as.numeric(sum(log(1 + exp(temp))) - data$y %*% temp + (theta %*% theta) / (2 * sd * sd)))
}
grad_U <- function(theta, data, sd = 10) {
temp <- data$x %*% theta
temp <- as.numeric(1/(1 + exp(-temp)) - data$y)
return(as.numeric(theta / (sd * sd) + temp %*% data$x))
}
load("German_Credit.RData")
d <- ncol(x)
N <- nrow(x)
data <- list(d = d, N = N, x = x, y = y)
load("/Users/jstoehr/git/eHMC/model/BLP/German_Credit.RData")
d <- ncol(x)
N <- nrow(x)
data <- list(d = d, N = N, x = x, y = y)
leapfrog <- function(theta, v, grad_U, eps, L, inv_M, data = NULL) {
new_theta <- theta
new_v <- v - 0.5 * eps * grad_U(theta, data)
for (l in 1:(L - 1)) {
new_theta <- new_theta + eps * as.numeric(inv_M %*% new_v)
new_v <- new_v - eps * grad_U(new_theta, data)
}
new_theta <- new_theta + eps * as.numeric(inv_M %*% new_v)
return(list(
theta = new_theta,
v = new_v - 0.5 * eps * grad_U(new_theta, data)
))
}
single_leapfrog <- function(theta, v, grad_U, eps, inv_M, data) {
new_v <- v - 0.5 * eps * grad_U(theta, data)
new_theta <- theta + eps * as.numeric(inv_M %*% new_v)
new_v <- new_v - 0.5 * eps * grad_U(new_theta, data)
return(list(theta = new_theta, v = new_v))
}
longest_batch <- function(theta, v, grad_U, eps, L,
inv_M, data = NULL, max_length = 2^12) {
prop <- list(theta = theta, v = v)
first_turn <- FALSE
cond <- 0
l <- L
for (i in 1:L) {
prop <- single_leapfrog(prop$theta, prop$v, grad_U, eps, inv_M, data)
cond <- as.numeric((prop$theta - theta) %*% (inv_M %*% prop$v))
if (is.na(cond)) {
return(list(
theta = theta, v = v, l = l,
first_turn = first_turn, div = TRUE
))
} else if (!first_turn && (cond < 0)) {
l <- i
first_turn <- TRUE
}
}
if (!first_turn) {
while (!first_turn && (l < max_length)) {
l <- l + 1
prop <- single_leapfrog(prop$theta, prop$v, grad_U, eps, inv_M, data)
cond <- as.numeric((prop$theta - theta) %*% (inv_M %*% prop$v))
if (is.na(cond)) {
return(list(
theta = theta, v = v, l = l,
first_turn = first_turn, div = TRUE
))
}
first_turn <- (cond < 0)
}
}
return(list(
theta = prop$theta, v = prop$v, l = l,
first_turn = first_turn, div = FALSE
))
}
learn_emp_dist <- function(theta, n_iter, U, grad_U, eps, L0,
inv_M, chol_M, data = NULL, max_length = 2^12) {
current_U <- U(theta, data)
dim_theta <- length(theta)
theta <- matrix(theta, n_iter + 1, dim_theta, byrow = TRUE)
ans <- data.frame(
rho = rep(0, n_iter), L = rep(L0, n_iter), l = rep(L0, n_iter),
first_turn = rep(F, n_iter), div = rep(F, n_iter)
)
for (i in 1:n_iter) {
current_v <- as.numeric(chol_M %*% rnorm(dim_theta))
current_K <- current_v %*% (inv_M %*% current_v)
L <- sample(1:L0, 1)
prop <- longest_batch(
theta[i, ], current_v, grad_U, eps, L, inv_M,
data, max_length
)
new_U <- U(prop$theta, data)
new_K <- prop$v %*% (inv_M %*% prop$v)
rho <- current_U - new_U + 0.5 * (current_K - new_K)
if (is.na(rho) || rho < log(runif(1))) {
theta[i + 1, ] <- theta[i, ]
} else {
theta[i + 1, ] <- prop$theta
current_U <- new_U
}
ans[i, ] <- c(rho, L, prop$l, prop$first_turn, prop$div)
}
return(data.frame(theta = theta[-1, ], ans))
}
eHMC <- function(theta, n_iter, U, grad_U, eps, emp_L,
inv_M, chol_M, data = NULL) {
current_U <- U(theta, data)
dim_theta <- length(theta)
theta <- matrix(theta, n_iter + 1, dim_theta, byrow = TRUE)
ans <- data.frame(
rho = rep(0, n_iter), L = rep(1, n_iter), div = rep(F, n_iter)
)
for (i in 1:n_iter) {
current_v <- as.numeric(chol_M %*% rnorm(dim_theta))
current_K <- current_v %*% (inv_M %*% current_v)
L <- sample(emp_L, 1)
prop <- leapfrog(theta[i, ], current_v, grad_U, eps, L, inv_M, data)
new_U <- U(prop$theta, data)
new_K <- prop$v %*% (inv_M %*% prop$v)
rho <- current_U - new_U + 0.5 * (current_K - new_K)
if (is.na(rho) || rho < log(runif(1))) {
theta[i + 1, ] <- theta[i, ]
} else {
theta[i + 1, ] <- prop$theta
current_U <- new_U
}
ans[i, ] <- c(rho, L, is.na(rho))
}
return(data.frame(theta = theta[-1, ], ans))
}
U_ <- function(theta)
{
val <- - log_prob(fit, theta)
return(val)
}
grad_U_ <- function(theta)
{
val <- - grad_log_prob(fit, theta)[1:d]
return(val)
}
load("/Users/jstoehr/git/eHMC/model/BLP/adapt_info_NUTS_BLP_diag_e_60_.RData")
theta <- start[1,]
U(theta, data)
-log_prob(fit, theta)
U_(theta)
grad_log_prob(fit, theta)
setwd("~/git/eHMC/model/BLP")
fit <- stan(BLP.stan,
data = data,
chains = 0
)
fit <- stan("BLP.stan",
data = data,
chains = 0
)
fit <- stan("BLP.stan", data = data, chains = 0)
fit_ <- stan("BLP.stan", data = data, chains = 0)
library(rstan)
fit_ <- stan("BLP.stan", data = data, chains = 0)
model_stan <- model.stan
n_chains <- 0
fit <- stan(model_stan,
data = data,
chains = n_chains,
iter = iter,
warmup = warmup,
save_dso = FALSE,
verbose = FALSE,
algorithm = "NUTS",
control = list(
adapt_engaged = TRUE, stepsize = 0.01, adapt_delta = delta,
metric = M_type, max_treedepth = 14
)
)
n_chains <- 1
fit <- stan(model_stan,
data = data,
chains = n_chains,
iter = iter,
warmup = warmup,
save_dso = FALSE,
verbose = FALSE,
algorithm = "NUTS",
control = list(
adapt_engaged = TRUE, stepsize = 0.01, adapt_delta = delta,
metric = M_type, max_treedepth = 14
)
)
